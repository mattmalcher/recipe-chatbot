{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from polars import DataFrame\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Labeled Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSONL file into a Polars DataFrame\n",
    "traces_path = Path(\"reference_files/labeled_traces.jsonl\")\n",
    "df: DataFrame = pl.read_ndjson(traces_path)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display schema to see nested structure\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline State Taxonomy\n",
    "\n",
    "| # | State | Description |\n",
    "|---|--------------------|-------------------------------------------|\n",
    "| 1 | `ParseRequest`     | LLM interprets the user's message         |\n",
    "| 2 | `PlanToolCalls`    | LLM decides which tools to invoke         |\n",
    "| 3 | `GenCustomerArgs`  | LLM constructs arguments for customer DB  |\n",
    "| 4 | `GetCustomerProfile` | Executes customer-profile tool         |\n",
    "| 5 | `GenRecipeArgs`    | LLM constructs arguments for recipe DB    |\n",
    "| 6 | `GetRecipes`       | Executes recipe-search tool               |\n",
    "| 7 | `GenWebArgs`       | LLM constructs arguments for web search   |\n",
    "| 8 | `GetWebInfo`       | Executes web-search tool                  |\n",
    "| 9 | `ComposeResponse`  | LLM drafts the final answer               |\n",
    "|10 | `DeliverResponse`  | Agent sends the answer                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pipeline State Taxonomy order (1-10)\n",
    "state_order = [\n",
    "    'ParseRequest',\n",
    "    'PlanToolCalls',\n",
    "    'GenCustomerArgs',\n",
    "    'GetCustomerProfile',\n",
    "    'GenRecipeArgs',\n",
    "    'GetRecipes',\n",
    "    'GenWebArgs',\n",
    "    'GetWebInfo',\n",
    "    'ComposeResponse',\n",
    "    'DeliverResponse'\n",
    "]\n",
    "\n",
    "state_numbers = {b:a+1 for a,b in enumerate(state_order)}\n",
    "state_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract State Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_state_sequence(messages):\n",
    "    \"\"\"\n",
    "    Extract numbered state sequence with USER_N and ASSISTANT_N labels.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of message dicts with 'role' and 'content' keys\n",
    "    \n",
    "    Returns:\n",
    "        List of state names/turns in order:\n",
    "        - \"USER_1\", \"USER_2\", etc. for user messages\n",
    "        - \"ASSISTANT_1\", \"ASSISTANT_2\", etc. for assistant messages without TOOL_CALL\n",
    "        - State name (e.g., \"ParseRequest\") for TOOL_CALL messages\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    pattern = r'TOOL_CALL\\[([^\\]]+)\\]'\n",
    "    user_count = 0\n",
    "    assistant_count = 0\n",
    "    \n",
    "    for msg in messages:\n",
    "        role = msg['role']\n",
    "        content = msg['content']\n",
    "        \n",
    "        # Check if this is a TOOL_CALL message\n",
    "        match = re.search(pattern, content)\n",
    "        if match:\n",
    "            state_name = match.group(1)\n",
    "            states.append(state_name)\n",
    "        else:\n",
    "            # Add numbered role-based labels for non-tool-call messages\n",
    "            if role.lower() == 'user':\n",
    "                user_count += 1\n",
    "                states.append(f'USER_{user_count}')\n",
    "            elif role.lower() in ['assistant', 'agent']:\n",
    "                assistant_count += 1\n",
    "                states.append(f'ASSISTANT_{assistant_count}')\n",
    "    \n",
    "    return states\n",
    "\n",
    "\n",
    "# Add state sequence column to dataframe\n",
    "df_with_states: DataFrame = df.with_columns(\n",
    "    pl.col('messages').map_elements(\n",
    "        extract_state_sequence, \n",
    "        return_dtype=pl.List(pl.String)\n",
    "    ).alias('state_sequence')\n",
    ")\n",
    "\n",
    "def truncate_at_first_failure(state_sequence, first_failure_state):\n",
    "    \"\"\"\n",
    "    Truncate state sequence after the first occurrence of the failure state.\n",
    "    \n",
    "    Args:\n",
    "        state_sequence: List of state strings\n",
    "        first_failure_state: The failure state to look for\n",
    "    \n",
    "    Returns:\n",
    "        Truncated list including states up to and including the first failure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        failure_idx = state_sequence.index(first_failure_state)\n",
    "        return state_sequence[:failure_idx + 1]  # Include the failure state\n",
    "    except ValueError:\n",
    "        # Failure state not in sequence, return full sequence\n",
    "        return state_sequence\n",
    "\n",
    "\n",
    "# Apply truncation to create truncated_sequence column\n",
    "df_with_states: DataFrame = df_with_states.with_columns(\n",
    "    pl.struct(['state_sequence', 'first_failure_state'])\n",
    "    .map_elements(\n",
    "        lambda x: truncate_at_first_failure(x['state_sequence'], x['first_failure_state']),\n",
    "        return_dtype=pl.List(pl.String)\n",
    "    ).alias('truncated_sequence')\n",
    ")\n",
    "\n",
    "# Analyze sequence lengths\n",
    "df_with_states: DataFrame = df_with_states.with_columns(\n",
    "    pl.col('state_sequence').list.len().alias('seq_len_all'),\n",
    "    pl.col('truncated_sequence').list.len().alias('seq_len_working')\n",
    ")\n",
    "\n",
    "# Display examples\n",
    "print(\"Sample state sequences with numbered USER/ASSISTANT turns:\")\n",
    "df_with_states.select(['conversation_id', 'truncated_sequence', 'last_success_state', 'first_failure_state', 'seq_len_all', 'seq_len_working']).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Pairs\n",
    "\n",
    "These are interesting, the top pairs are going to be the ones we mostly care about, but there is a long tail as well.\n",
    "\n",
    "The tail includes some transitions you might not expect:\n",
    "* PlanToolCalls -> DeliverResponse (giving up immediately eh!)\n",
    "* GenCustomerArgs -> ComposeResponse\n",
    "\n",
    "... why is it ever allowed to call gen args and then not call the tool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each (last_success_state, first_failure_state) pairing\n",
    "state_pairs: DataFrame = (\n",
    "    df_with_states.group_by(\n",
    "        [\n",
    "            \"last_success_state\",\n",
    "            \"first_failure_state\",\n",
    "            #\"seq_len_working\"\n",
    "        ]\n",
    "    )\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ").with_columns([\n",
    "    (\n",
    "        pl.col(\"first_failure_state\").replace_strict(state_numbers, default=None) -\n",
    "        pl.col(\"last_success_state\").replace_strict(state_numbers, default=None)\n",
    "    ).alias(\"state_jump\")\n",
    "])\n",
    "\n",
    "print(f\"Total unique pairings: {len(state_pairs)}\")\n",
    "state_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Transition Heatmap\n",
    "\n",
    "Looking at this heatmap, the failures are around generating the arguments for the search tool, and then the handling of getting no results. Past that, to the right, failures are less common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "# Create heatmap showing prevalence of state pairings\n",
    "\n",
    "\n",
    "heatmap = alt.Chart(state_pairs).mark_rect().encode(\n",
    "    x=alt.X('first_failure_state:N',\n",
    "            title='First Failure State',\n",
    "            axis=alt.Axis(labelAngle=-45),\n",
    "            sort=state_order),\n",
    "    y=alt.Y('last_success_state:N',\n",
    "            title='Last Success State',\n",
    "            sort=state_order),\n",
    "    color=alt.Color('count:Q',\n",
    "                    title='Count',\n",
    "                    scale=alt.Scale(scheme='viridis')),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('first_failure_state:N', title='First Failure'),\n",
    "        alt.Tooltip('last_success_state:N', title='Last Success'),\n",
    "        alt.Tooltip('count:Q', title='Count')\n",
    "    ]\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=400,\n",
    "    title='State Transition Prevalence: Last Success → First Failure'\n",
    ")\n",
    "\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polars import DataFrame\n",
    "\n",
    "# TODO - make this highlight the error step\n",
    "# TODO - make this put out the row number in the dataframe - the viewer page doesnt take the id,\n",
    "\n",
    "def get_examples_for_top_pairings(\n",
    "    df: DataFrame,\n",
    "    state_pairs: DataFrame,\n",
    "    top_n: int = 5,\n",
    "    examples_per_pairing: int = 2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get example conversations for the most prevalent state pairings.\n",
    "\n",
    "    Args:\n",
    "        df: Original dataframe with conversation data\n",
    "        state_pairs: Dataframe with state pairing counts\n",
    "        top_n: Number of top pairings to show examples for\n",
    "        examples_per_pairing: Number of example conversations per pairing\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping (last_success, first_failure) to list of example conversations\n",
    "    \"\"\"\n",
    "    examples: dict[Unknown, Unknown] = {}\n",
    "\n",
    "    # Get top N pairings\n",
    "    top_pairings = state_pairs.head(top_n)\n",
    "\n",
    "    for row in top_pairings.iter_rows(named=True):\n",
    "        last_success = row[\"last_success_state\"]\n",
    "        first_failure = row[\"first_failure_state\"]\n",
    "        count = row[\"count\"]\n",
    "\n",
    "        # Filter conversations matching this pairing\n",
    "        matching = df.filter(\n",
    "            (pl.col(\"last_success_state\") == last_success)\n",
    "            & (pl.col(\"first_failure_state\") == first_failure)\n",
    "        ).head(examples_per_pairing)\n",
    "\n",
    "        # Store examples\n",
    "        key = (last_success, first_failure, count)\n",
    "        examples[key] = matching.to_dicts()\n",
    "\n",
    "    return examples\n",
    "\n",
    "# TODO - make this render something nicer than plain text - can we generate markdown in jupyter from python and have it render?\n",
    "def print_example_conversations(examples):\n",
    "    \"\"\"\n",
    "    Pretty print example conversations for state pairings.\n",
    "    \"\"\"\n",
    "    for (last_success, first_failure, count), conversations in examples.items():\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Pairing: {last_success} → {first_failure} (Count: {count})\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        for i, conv in enumerate(conversations, 1):\n",
    "            print(f\"\\n--- Example {i} ---\")\n",
    "            print(f\"Conversation ID: {conv['conversation_id']}\")\n",
    "            print(f\"\\nMessages:\")\n",
    "            for msg in conv[\"messages\"]:\n",
    "                role = msg[\"role\"].upper()\n",
    "                content = msg[\"content\"]\n",
    "                print(f\"  [{role}]: {content}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"PlanToolCalls\" -> \"GenRecipeArgs\"\t10\n",
    "\n",
    "Looking at a few of these perhaps the issue is that the users are expressing some requirement which doesnt align with the tool arguments?\n",
    "\n",
    "> Error: unable to generate appropriate recipe search parameters\n",
    "\n",
    "> Error: Unable to generate recipe search parameters\n",
    "\n",
    "> Error: Unable to generate recipe arguments from the provided request.\n",
    "\n",
    "> Error: unable to generate recipe arguments due to missing or incompatible input data.\n",
    "\n",
    "> Error: unable to generate appropriate recipe arguments based on the provided dietary and serving information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = get_examples_for_top_pairings(df, state_pairs[0], top_n=1, examples_per_pairing=5)\n",
    "print_example_conversations(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# \"GetCustomerProfile\" -> \"GetRecipes\"\t9\n",
    "\n",
    "* Several of these are the same query (` I need a gluten-free dinner idea for four`) - and it looks like there arent any in the db.\n",
    "    * Not sure this is a _failure_ - its correctly saying it doesnt have any recipes for that requirement\n",
    "* `7e827a7a-6114-460e-844d-9afcad1410b8` looks like perhaps the retriever was broken at the point of query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = get_examples_for_top_pairings(df, state_pairs[1], top_n=1, examples_per_pairing=5)\n",
    "print_example_conversations(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"GenCustomerArgs\"\t-> \"GetRecipes\"\t8\n",
    "\n",
    "So - these look like the same failure modes on the GetRecipes, its just that for whatever reason the planner didnt put in the GetCustomerProfile tool call first for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = get_examples_for_top_pairings(df, state_pairs[2], top_n=1, examples_per_pairing=5)\n",
    "print_example_conversations(examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recipe-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
